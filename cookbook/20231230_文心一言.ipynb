{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-29T09:07:24.866926200Z",
     "start_time": "2023-12-29T09:07:19.862805500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'苏轼（1037年1月8日—1101年8月24日），字子瞻，号东坡居士，世称苏东坡、苏仙、坡仙，是宋代著名的文学家、书法家、画家和政治家，也是一位美食家和医药爱好者。\\n\\n苏轼是北宋中期文坛的领袖人物，在诗、词、散文方面取得很高的成就。他的文章纵横恣肆，为“唐宋八大家”之一。他的书法与蔡襄、黄庭坚、米芾合称“宋四家”，影响很大。在绘画方面，他善画山水，自成一家，开创了湖州画派。他的作品有诗文集《东坡七集》和《东坡易传》等。\\n\\n除此之外，苏轼在医药方面也很有造诣。他是一个受禅宗影响极深的文人，参禅吃素对他养生有好处。他认为药补不如食补，食物是最好的医药。他喜好烹饪，对食品的加工颇有研究，还著有《苏学士食单》和《苏沈良方》等美食专著。\\n\\n苏轼在任职期间，曾多次被贬或遭流放。但他始终乐观向上，善于从自然万物中寻找乐趣和启迪。他喜爱游览名山大川，常常借物咏怀，抒发情感。他在逆境中不断寻找生活中的美好事物，并用自己的方式将其表现出来，成为了中国古代文学史上的一个重要人物。\\n\\n总的来说，苏轼是一位才华横溢的文化名人，他对诗词、书法、绘画、医药等多个领域都有深厚的造诣和贡献。'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chat_models import QianfanChatEndpoint\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"介绍一下{who}。\")\n",
    "content = prompt.format(who='苏轼')\n",
    "chat = QianfanChatEndpoint()\n",
    "chat([HumanMessage(content=content)]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from libs.community.langchain_community.embeddings.ernie import ErnieEmbeddings\n",
    "from libs.community.langchain_community.llms.baidu_qianfan_endpoint import QianfanLLMEndpoint\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "import os\n",
    "\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at coffee shop\", \"bears like to eat honey\"],\n",
    "    embedding=ErnieEmbeddings(),\n",
    "    # embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = QianfanLLMEndpoint()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# resp = chain.invoke(\"where did harrison work?\")\n",
    "# print(resp)\n",
    "for chunk in chain.stream(\"where did harrison work?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T02:40:55.015719Z",
     "start_time": "2024-01-04T02:34:55.785643700Z"
    }
   },
   "id": "1f753d75c93b288a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'好的，根据提供的信息，以下是中文的回答：\\n\\nHarrison在Kensho工作。'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\":  itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language2\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"where did harrison work\", \"language2\": \"chinese\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T05:42:17.276423300Z",
     "start_time": "2023-12-30T05:42:15.385096800Z"
    }
   },
   "id": "ee6f5c7f9d62a5db"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='Yes, it is true that Harrison worked at Kensho.')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from libs.community.langchain_community.chat_models.openai import ChatOpenAI\n",
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "\n",
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "input_raw = {\n",
    "        \"question\": \"Really??\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"where did harrison work?\"),\n",
    "            AIMessage(content='Harrison worked at Kensho.'),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "invoke = _inputs.invoke(input_raw)\n",
    "context__invoke = RunnableParallel(_context).invoke(invoke)\n",
    "prompt_invoke = ANSWER_PROMPT.invoke(context__invoke)\n",
    "ChatOpenAI().invoke(prompt_invoke)\n",
    "# (_context | ANSWER_PROMPT | ChatOpenAI()).invoke(invoke)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T06:43:26.510209100Z",
     "start_time": "2023-12-30T06:43:23.988726300Z"
    }
   },
   "id": "cbd8dd5614fc9629"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': [HumanMessage(content='where did harrison work?'),\n  AIMessage(content='Harrison was employed at Kensho.')]}"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.runnables.base import RunnableLambda\n",
    "from operator import itemgetter\n",
    "from libs.langchain.langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 首先需要加载缓冲的聊天记录\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "\n",
    "# 把问题，和聊天记录，整成一个问题\n",
    "standalone_question = RunnableParallel({\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser(),\n",
    "})\n",
    "\n",
    "# 根据整好的问题，从知识库当中检索答案\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "\n",
    "# 把知识库内容，问题，丢给LLM，然后LLM返回答案，知识库内容保持不变\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "\n",
    "input_raw = {\"question\": \"where did harrison work?\"}\n",
    "memory_invoke = loaded_memory.invoke(input_raw)\n",
    "question_invoke = standalone_question.invoke(memory_invoke)\n",
    "documents__invoke = RunnableParallel(retrieved_documents).invoke(question_invoke)\n",
    "result = RunnableParallel(answer).invoke(documents__invoke)\n",
    "result\n",
    "\n",
    "memory.save_context(input_raw, {\"answer\": result[\"answer\"].content})\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:32:24.941760500Z",
     "start_time": "2023-12-30T07:32:19.163174200Z"
    }
   },
   "id": "20a5284c0f4a8dc1"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': [HumanMessage(content='where did harrison work?'),\n  AIMessage(content='Harrison was employed at Kensho.')]}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:34:32.471068800Z",
     "start_time": "2023-12-30T07:34:32.454039400Z"
    }
   },
   "id": "82da3226fbb14d39"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': [HumanMessage(content='where did harrison work?'),\n  AIMessage(content='Harrison was employed at Kensho.'),\n  HumanMessage(content='but where did he really work?'),\n  AIMessage(content='Harrison actually worked at Kensho.')]}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_raw2 = {\"question\": \"but where did he really work?\"}\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer\n",
    "result = final_chain.invoke(input_raw2)\n",
    "memory.save_context(input_raw2, {\"answer\": result[\"answer\"].content})\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:37:25.609846800Z",
     "start_time": "2023-12-30T07:37:22.821581700Z"
    }
   },
   "id": "f3b1f60433054497"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "'毛泽东，又被称为主席毛，来自中国湖南省韶山市。'"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what country is the city {city} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"city\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"person\": \"毛泽东\", \"language\": \"chinese\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:48:31.053414800Z",
     "start_time": "2023-12-30T07:48:28.369061Z"
    }
   },
   "id": "79c1d02825108317"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptValue(messages=[HumanMessage(content='What is the color of Marigold and the flag of Antigua and Barbuda?')])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"generate a {attribute} color. Return the name of the color and nothing else:\"\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\"\n",
    ")\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\"\n",
    ")\n",
    "prompt4 = ChatPromptTemplate.from_template(\n",
    "    \"What is the color of {fruit} and the flag of {country}?\"\n",
    ")\n",
    "\n",
    "model_parser = model | StrOutputParser()\n",
    "\n",
    "color_generator = (\n",
    "    {\"attribute\": RunnablePassthrough()} | prompt1 | {\"color\": model_parser}\n",
    ")\n",
    "color_to_fruit = prompt2 | model_parser\n",
    "color_to_country = prompt3 | model_parser\n",
    "question_generator = (\n",
    "    color_generator | {\"fruit\": color_to_fruit, \"country\": color_to_country} | prompt4\n",
    ")\n",
    "question_generator.invoke(\"warm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T07:58:24.837731800Z",
     "start_time": "2023-12-30T07:58:22.871462400Z"
    }
   },
   "id": "1d36c55ebc2ddeb1"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "{'results_1': '正方观点总结：品德高于情商，因为品德决定了一个人如何对待他人和自己，具有高品德的人会采取正确的行为和决策，建立可靠和稳固的人际关系。品德也是社会责任感的表现，高品德的人会参与公益活动并帮助他人。\\n\\n反方观点总结：情商高于品德，因为情商可以帮助人们更好地处理情感和人际关系，应对压力和挑战，并促进个人的成功。在现代社会中，人际关系和合作能力对个人的成功至关重要，情商高的人更容易与他人合作并建立良好的合作关系。',\n 'results_2': '4. 情商可以帮助人们更好地适应现代社会的快节奏和高压力环境。在现代社会中，人们常常面临各种压力和挑战，情商高的人可以更好地应对这些挑战，保持积极的心态和情绪稳定。\\n\\n5. 情商可以提高个人的领导能力。一个情商高的人通常具备良好的沟通和影响力，能够有效地领导和管理团队，实现集体目标。\\n\\n6. 情商可以促进个人的自我认知和成长。通过提高情商，人们可以更好地了解自己的情感和行为模式，从而更好地发展个人潜力和实现自我成长。\\n\\n7. 情商可以帮助人们更好地处理人际关系和冲突。情商高的人通常能够更好地理解他人的情感和需求，并能够通过有效的沟通和解决冲突的能力来维护良好的人际关系。\\n\\n8. 情商可以提高个人的创造力和创新能力。情商高的人通常能够更好地理解自己和他人的需求，并能够提出创新的解决方案和新的思维方式。\\n\\n总结：\\n\\n反方认为情商高于品德，因为情商可以帮助人们更好地适应现代社会的快节奏和高压力环境，提升个人的领导能力，促进自我认知和成长，处理人际关系和冲突，以及提高创造力和创新能力。这些观点强调了情商在个人发展和成功方面的重要性。',\n 'original_response': '正方：品德高于情商\\n\\n1. 品德是一个人的核心价值观和道德准则，它决定了一个人如何对待他人和自己。一个有高尚品德的人会采取正确的行为和决策，从而建立起可靠和稳固的人际关系。\\n\\n2. 品德可以使一个人更加善良和宽容。一个具有高品德的人在面对困难和挫折时，会以一种积极的态度去应对，而不是通过欺骗或背叛他人来达到自己的目标。\\n\\n3. 品德是一个人的社会责任感的表现。高品德的人会主动参与公益活动，为社会做出贡献。他们愿意帮助那些需要帮助的人，并且具备良好的团队合作精神。\\n\\n反方：情商高于品德\\n\\n1. 情商是一个人在处理情感和人际关系方面的能力。一个具有高情商的人可以更好地理解和掌握自己的情绪，并且能够与他人建立良好的沟通和关系。\\n\\n2. 情商可以帮助人们更好地应对压力和挑战。一个情商高的人可以更好地处理复杂的情绪和冲突，从而更好地应对各种困难和挑战。\\n\\n3. 情商可以促进个人的成功。在现代社会中，人际关系和合作能力对于个人的成功至关重要。一个情商高的人可以更好地与他人合作，建立良好的合作关系，并且更容易获得成功。\\n\\n总结：\\n\\n正方认为品德高于情商，因为品德是一个人的核心价值观和道德准则，决定了一个人如何对待他人和自己。品德高的人会采取正确的行为和决策，建立可靠和稳固的人际关系。反方认为情商高于品德，因为情商可以帮助人们更好地处理情感和人际关系，应对压力和挑战，并促进个人的成功。这场辩论可以引发对于品德和情商的重要性的思考和讨论。'}"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner = (\n",
    "    ChatPromptTemplate.from_template(\"生成一场正反方的辩论。主题是: {input}\")\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    "    | {\"base_response\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "arguments_for = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"列出正方观点，基于： {base_response}\"\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "arguments_against = (\n",
    "    ChatPromptTemplate.from_template(\n",
    "        \"列出反方观点，基于： {base_response}\"\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_responder = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"ai\", \"{original_response}\"),\n",
    "            (\"human\", \"正反:\\n{results_1}\\n\\n反方:\\n{results_2}\"),\n",
    "            (\"system\", \"给出一个最终判定，谁赢了\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "planner_invoke = planner.invoke({\"input\": \"品德高于情商\"})\n",
    "RunnableParallel(\n",
    "    {\n",
    "        \"results_1\": arguments_for,\n",
    "        \"results_2\": arguments_against,\n",
    "        \"original_response\": itemgetter(\"base_response\"),\n",
    "    }\n",
    ").invoke(planner_invoke)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T08:21:12.899200100Z",
     "start_time": "2023-12-30T08:20:42.761760500Z"
    }
   },
   "id": "5be54e505bbff584"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
