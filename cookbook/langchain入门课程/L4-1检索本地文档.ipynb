{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# 检索本地文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = QianfanEmbeddingsEndpoint(model=\"bge_large_zh\", endpoint=\"bge_large_zh\")\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249846e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# loader = CSVLoader(file_path='京东评论100.csv',encoding='utf-8',source_column='评论内容',metadata_columns=[\"型号\"])\n",
    "loader = CSVLoader(file_path='京东评论100.csv',encoding='utf-8')\n",
    "docs = loader.load()\n",
    "docs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "构建内存向量库\n",
    "'''\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")\n",
    "\n",
    "'''\n",
    "根据问题，找出相似度最高的评论\n",
    "'''\n",
    "query =\"哪个型号比较美观\"\n",
    "# query = \"哪个型号比较护眼\"\n",
    "related_docs = db.similarity_search(query)\n",
    "related_docs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bd5cbe3a7ccb823"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature = 0.0)\n",
    "qdocs = \"\\n\\n\".join([related_docs[i].page_content for i in range(len(related_docs))])\n",
    "prompt = f\"{qdocs} Question: {query}\"\n",
    "llm.invoke(prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49ee5b5a981d9422"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "比较余弦相似度\n",
    "'''\n",
    "import numpy as np\n",
    "# 余弦相似度。-1到1之间，值越大表示相似度越高\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "query =\"哪个型号比较美观\"\n",
    "embedding1 = embeddings.embed_query(query)\n",
    "\n",
    "txt1 = '''\n",
    "型号: 2022时尚\\n评论内容: 很快 外观大气漂亮\n",
    "'''\n",
    "embedding2 = embeddings.embed_query(txt1)\n",
    "\n",
    "txt2='''\n",
    "型号: 2023豪华\\n评论内容: 很不错，还没有开机，但是速度还可以  外观也不错\n",
    "'''\n",
    "embedding3 = embeddings.embed_query(txt2)\n",
    "\n",
    "distance12 = cosine_similarity(embedding1, embedding2)\n",
    "distance13 = cosine_similarity(embedding1, embedding3)\n",
    "print(f'distance12:{distance12}\\ndistance13:{distance13}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21981b4cc681c1c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c94d22",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False\n",
    "retriever = db.retriever()\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type = \"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "qa_stuff.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "尝试不同参数类型。\n",
    "\"map_reduce\"\n",
    "'''\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.llms.baidu_qianfan_endpoint import QianfanLLMEndpoint\n",
    "\n",
    "llm = QianfanLLMEndpoint(temperature=0.1)\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "loader = TextLoader(file_path='客服.txt',encoding='utf-8')\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 3000,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "len(split_documents)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab5e12afbf624701"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    split_documents, \n",
    "    embeddings\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7da4a56715bdd4e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "langchain.debug=True\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "# llm = QianfanLLMEndpoint(temperature=0.1)\n",
    "retriever = db.as_retriever()\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type = \"map_reduce\",\n",
    "    retriever=retriever\n",
    ")\n",
    "query = \"他们主要谈了什么内容\"\n",
    "qa_stuff.run(query)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3291bfd1fcf78ada"
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='# 糖醋排骨做法\\n- 1、准备用料，排骨300克；菠萝适量；洋葱适量；老姜少许；葱少许；蒜瓣少许；生粉少许；老抽少许；白醋少许；料酒少许；盐适量；白糖少许\\n- 2、洋葱切块，姜切片、葱切断，蒜瓣两个 菠萝一般切小粒，一般切块 排骨提前用清水，泡去血水，取出，沥下水\\n- 3、生粉，姜片，部分洋葱，生抽 拌匀，腌制排骨15-20分钟\\n- 4、小锅子放适量油，腌制好的排骨入锅大火炸40秒左右\\n- 5、关火，余温继续炸1分钟  取出沥油  锅中放适量炸排骨的油\\n- 6、放洋葱、蒜瓣、姜片拌炒爆香  放炸好的排骨，拌炒\\n- 7、放菠萝小粒  放生抽  放白醋  放少许老抽，白糖一点点  拌炒均匀  放入葱段，加适量清水，没过排骨的量\\n- 8、盖上锅盖大火煮开，继续煮5分钟  转中火焖煮，中间加盐，调味，煮至熟烂\\n- 9、最后转大火收治，关火，再放菠萝块拌炒出锅', metadata={'source': '使用手册.md'})]"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "使用 refine\n",
    "'''\n",
    "loader = TextLoader(file_path='使用手册.md',encoding='utf-8')\n",
    "docs = loader.load()\n",
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T02:42:17.931564400Z",
     "start_time": "2024-01-14T02:42:17.916565600Z"
    }
   },
   "id": "848b3de17ae1ac68"
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 40,\n",
    "    chunk_overlap = 0,\n",
    "    separators=['\\n']\n",
    ")\n",
    "split_documents = text_splitter.split_documents(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T02:42:24.915939Z",
     "start_time": "2024-01-14T02:42:24.904940200Z"
    }
   },
   "id": "78bf34cec8f5c2e9"
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"query\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain] Entering Chain run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"\\n- 2、洋葱切块，姜切片、葱切断，蒜瓣两个 菠萝一般切小粒，一般切块 排骨提前用清水，泡去血水，取出，沥下水\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 4:chain:LLMChain > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Context information is below.\\n------------\\n\\n- 2、洋葱切块，姜切片、葱切断，蒜瓣两个 菠萝一般切小粒，一般切块 排骨提前用清水，泡去血水，取出，沥下水\\n------------\\nGiven the context information and not prior knowledge, answer any questions\\nHuman: 先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 4:chain:LLMChain > 5:llm:ChatOpenAI] [1.09s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"先腌制排骨。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"先腌制排骨。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 9,\n",
      "      \"prompt_tokens\": 140,\n",
      "      \"total_tokens\": 149\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 4:chain:LLMChain] [1.09s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"先腌制排骨。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 6:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"- 3、生粉，姜片，部分洋葱，生抽 拌匀，腌制排骨15-20分钟\",\n",
      "  \"existing_answer\": \"先腌制排骨。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 6:chain:LLMChain > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 先腌制排骨。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n- 3、生粉，姜片，部分洋葱，生抽 拌匀，腌制排骨15-20分钟\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 6:chain:LLMChain > 7:llm:ChatOpenAI] [892ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先切洋葱。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先切洋葱。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 141,\n",
      "      \"total_tokens\": 159\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 6:chain:LLMChain] [892ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先切洋葱。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 8:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"- 6、放洋葱、蒜瓣、姜片拌炒爆香  放炸好的排骨，拌炒\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先切洋葱。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 8:chain:LLMChain > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先切洋葱。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n- 6、放洋葱、蒜瓣、姜片拌炒爆香  放炸好的排骨，拌炒\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 8:chain:LLMChain > 9:llm:ChatOpenAI] [1.09s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先腌制排骨。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先腌制排骨。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 158,\n",
      "      \"total_tokens\": 176\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 8:chain:LLMChain] [1.09s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先腌制排骨。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 10:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"\\n- 1、准备用料，排骨300克；菠萝适量；洋葱适量；老姜少许；葱少许；蒜瓣少许；生粉少许；老抽少许；白醋少许；料酒少许；盐适量；白糖少许\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先腌制排骨。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 10:chain:LLMChain > 11:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先腌制排骨。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n\\n- 1、准备用料，排骨300克；菠萝适量；洋葱适量；老姜少许；葱少许；蒜瓣少许；生粉少许；老抽少许；白醋少许；料酒少许；盐适量；白糖少许\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 10:chain:LLMChain > 11:llm:ChatOpenAI] [978ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先切洋葱。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先切洋葱。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 215,\n",
      "      \"total_tokens\": 233\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 10:chain:LLMChain] [981ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先切洋葱。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 12:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"- 4、小锅子放适量油，腌制好的排骨入锅大火炸40秒左右\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先切洋葱。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 12:chain:LLMChain > 13:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先切洋葱。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n- 4、小锅子放适量油，腌制好的排骨入锅大火炸40秒左右\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 12:chain:LLMChain > 13:llm:ChatOpenAI] [1.04s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先腌制排骨。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先腌制排骨。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 146,\n",
      "      \"total_tokens\": 164\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 12:chain:LLMChain] [1.04s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先腌制排骨。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 14:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"- 5、关火，余温继续炸1分钟  取出沥油  锅中放适量炸排骨的油\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先腌制排骨。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 14:chain:LLMChain > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先腌制排骨。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n- 5、关火，余温继续炸1分钟  取出沥油  锅中放适量炸排骨的油\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 14:chain:LLMChain > 15:llm:ChatOpenAI] [956ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先切洋葱。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先切洋葱。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 155,\n",
      "      \"total_tokens\": 173\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 14:chain:LLMChain] [956ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先切洋葱。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 16:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"\\n- 7、放菠萝小粒  放生抽  放白醋  放少许老抽，白糖一点点  拌炒均匀  放入葱段，加适量清水，没过排骨的量\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先切洋葱。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 16:chain:LLMChain > 17:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先切洋葱。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n\\n- 7、放菠萝小粒  放生抽  放白醋  放少许老抽，白糖一点点  拌炒均匀  放入葱段，加适量清水，没过排骨的量\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 16:chain:LLMChain > 17:llm:ChatOpenAI] [930ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，先腌制排骨。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，先腌制排骨。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 18,\n",
      "      \"prompt_tokens\": 190,\n",
      "      \"total_tokens\": 208\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 16:chain:LLMChain] [931ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，先腌制排骨。\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 18:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"context_str\": \"# 糖醋排骨做法\",\n",
      "  \"existing_answer\": \"根据提供的新信息，先腌制排骨。\",\n",
      "  \"question\": \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 18:chain:LLMChain > 19:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 先腌制排骨，还是先切洋葱。不要多说废话\\nAI: 根据提供的新信息，先腌制排骨。\\nHuman: We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n# 糖醋排骨做法\\n------------\\nGiven the new context, refine the original answer to better answer the question. If the context isn't useful, return the original answer.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 18:chain:LLMChain > 19:llm:ChatOpenAI] [937ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"根据提供的新信息，我们可以先切洋葱。\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"根据提供的新信息，我们可以先切洋葱。\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 20,\n",
      "      \"prompt_tokens\": 124,\n",
      "      \"total_tokens\": 144\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain > 18:chain:LLMChain] [938ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"根据提供的新信息，我们可以先切洋葱。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA > 3:chain:RefineDocumentsChain] [7.93s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output_text\": \"根据提供的新信息，我们可以先切洋葱。\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RetrievalQA] [8.23s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"result\": \"根据提供的新信息，我们可以先切洋葱。\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'根据提供的新信息，我们可以先切洋葱。'"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    split_documents, \n",
    "    embeddings\n",
    ")\n",
    "langchain.debug=True\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 8})\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    # chain_type = \"map_reduce\",\n",
    "    chain_type = \"refine\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")\n",
    "query = \"先腌制排骨，还是先切洋葱。不要多说废话\"\n",
    "qa_stuff.run(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T03:12:53.961549100Z",
     "start_time": "2024-01-14T03:12:44.870219700Z"
    }
   },
   "id": "ef46888a41791832"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
